

[TOC]

### DRE-SLAM: Dynamic RGB-D Encoder SLAM for a Differential-Drive Robot

#### 摘要

摘要：先进的视觉同时定位和制图（V-SLAM）系统具有高精度的定位功能和令人印象深刻的映射效果。但是，大多数这些系统都假定操作环境是静态的，因此限制了它们在实际动态世界中的应用。在本文中，通过将RGB-D摄像机和安装在差动驱动机器人上的两个编码器的信息融合在一起，我们旨在估算机器人的运动并在动态和静态环境中构造静态背景OctoMap。提出了一种基于紧密耦合特征的方法，基于优化将两种信息融合在一起。
检测并剔除动态对象所占据的动态像素，以应对动态环境。可以使用在预定义和未定义的动态对象上识别动态像素的功能，这归因于基于CPU的对象检测方法和基于多视图约束的方法的结合。我们首先使用关键帧构造本地子OctoMap，然后将子OctoMap融合为完整的OctoMap。这种基于子图的方法使OctoMap能够变形，并显着减少了地图更新时间和内存成本。我们在各种动态和静态场景中评估了提出的系统。结果表明，我们的系统具有具有竞争力的姿态精度和高鲁棒性，并且能够在动态场景中构造干净的静态OctoMap。

#### 引言

视觉同时定位和地图绘制（V-SLAM）为室内移动机器人提供定位和感知功能。最新的V-SLAM算法可实现高精度的姿态估计并提供令人印象深刻的地图[1-3]。大多数V-SLAM方法在静态场景中表现良好，而在充满移动物体的动态场景中往往会失败。典型的动态场景包括人，动物，机器或车辆在运动的房屋，办公室和工厂。
此外，移动机器人导航需要合适的密集地图表示。尽管有许多突破性的方法来进行密集映射[2,3]，但大多数方法都无法应对动态场景。大多数密集映射方法都假设一个静态世界。他们将动态对象构建到地图中，这不适合机器人导航。本文旨在同时估计机器人姿势，并为在真实动态室内场景下工作的差动驱动机器人构建静态背景密集图。

在缺乏挑战性的场景中，例如缺乏纹理的场景或涉及快速运动的情况下，纯V-SLAM易碎[4]。尤其是在动态环境中，可能没有足够的静态像素进行估计。应用惯性测量单元（IMU）可以有效地提高惯性测量单元的鲁棒性V-SLAM系统[5]。作为IMU的替代品，轮编码器对于在二维（2D）平面上移动的差动驱动机器人具有独特的优势。由于数据处理简单，编码器不需要初始化，编码器测量值不会随温度漂移，并且编码器集成度不会随时间变化。编码器的集成度随距离而变化，而编码器仅适用于2D运动。

动态环境的本地化和密集映射需要逐像素动态数据检测。语义分割[6]和实例分割[7-11]允许在像素级别检测预定义的动态对象。但是，这些方法严重依赖于图形处理单元（GPU），这对于大多数室内移动机器人而言成本很高。此外，很难预先确定许多物体在运动或静止状态。例如，椅子可能被某人拉扯，或者可能是静止的。在这些情况下，语义分割和实例分割可能无法正常工作。

点云[12]，surfel[2]和volumetric[13,14]表示是三种常用的密集环境表示[4]。与其他两种表示方式不同，体积表示可以直接用于路径规划[8]。 OctoMap [14]是一种流行的基于体积的机器人导航表示。它允许紧凑的内存表达，并提供以下三种类型的信息：占用，空闲和未知。但是，OctoMap具有以下缺点：它不可变形，这意味着应在闭环后通过重新处理所有原始原始数据来重建整个地图。该过程耗时且占用大量内存。

为了解决这些问题，我们提出了一种SLAM系统，该系统可以在动态和静态环境中运行。拟议的系统利用了RGB-D摄像机和两个轮编码器的信息，这是差动驱动机器人的常见配置。输出为2D机器人姿势和静态背景的OctoMap。我们将系统命名为DRE-SLAM（动态RGB-D编码器SLAM）。 DRE-SLAM是基于基于特征的稀疏V-SLAM方法构建的。

通过使用优化，它可以将RGB-D摄像机和轮式编码器的信息紧密融合在一起，从而生成一系列具有高精度姿势的关键帧（KF）。检测并删除关键帧中的动态像素，以消除运动对象的干扰。基于无动态关键帧，我们构建了静态背景OctoMap。主要贡献概述如下：

- 一个基于优化的强大而准确的框架，可将RGB-D摄像机和两个轮式编码器的信息融合在一起，以实现动态环境。

- 一种动态像素检测和剔除方法，不需要GPU，并且可以在预定义和未定义的移动对象上检测动态像素。

- 基于子图的OctoMap构造方法，可以加快重建过程并减少内存消耗。

进行了各种评估，以测试DRE-SLAM在动态和静态环境中的性能。结果表明，我们的系统在动态和静态环境下均具有竞争性的准确性和鲁棒性。 OctoMap不受移动对象的影响。开源实现，数据集和视频可在以下网址获得。

本文的其余部分安排如下。第2部分简要回顾了用于静态和动态环境的传感器融合方法，关键技术和流行的SLAM方法。第3节介绍了要解决的问题的初步知识，假设和定义。第4节详细介绍了建议的DRE-SLAM系统。
第5节在准确性，地图质量和鲁棒性方面将建议的方法与最新系统进行了比较。此外，还测试了主要模块的性能。最后，我们在第6节中完成工作。

#### 相关工作

#####  传感器融合

单个传感器具有独特的优势和局限性。组合多个传感器可以有效地提高SLAM系统的性能[15]。常用的传感器配置是视觉加IMU，这会导致视觉惯性SLAM（VI-SLAM）。 VI-SLAM方法（例如VINS-Mono [5]）在动态环境中非常可靠。最近，Tristan等人[16]提出了一个密集的RGB-D-Inertial-SLAM系统。但是，它仅限于静态环境。与VI-SLAM相比，视觉编码器SLAM（VE-SLAM）方法的研究仍然相对较少。与在2D平面上移动的机器人的IMU相比，编码器具有特别的优势。代表性的优点是编码器测量值的积分随距离变化，而IMU测量值的积分随时间变化。 VE-SLAM方法可以长时间处理室内无纹理的场景，例如白墙。 RTAB-MAP [15]是一种通用系统，可以将RGB-D图像与车轮里程计牢固地结合在一起。但是，它无法处理动态环境。此外，本地机器人姿态估计仅使用车轮里程计而不耦合视觉信息。在本文中，我们同时使用编码器和RGB-D信息来估计每帧的机器人姿势。

#####  动态像素检测

识别动态图像像素是应对动态环境的关键。近年来，已经探索了几种方法。第一种方法依赖于深度学习技术，例如语义分割[6]和实例分割[7-11]。该方法可以在像素级别检测预定义的动态对象，但是对于未定义的移动对象或具有不确定运动属性的对象无法执行任何操作。此外，对GPU的大量需求限制了其在家用室内机器人上的应用。
第二种方法利用了多视图几何[6,9,17]引入的约束。假定静态像素满足多视图几何模型，而动态像素不满足。
但是，该方法通常使用阈值来确定像素的动态和静态属性，这很容易导致过度识别或识别不足。例如，长时间静止不动的人可能被错误地认为是静止的，并被添加到地图上。
第三种方法使用背景[18]或前景[19]检测算法。它的大多数实现都依赖于GPU，无法实时运行。第四种方法是场景流[8,20,21]或光学流[22]方法，它基于动态对象遵循不同运动模式的事实。该方法具有与基于多视图约束的方法类似的缺点。由于单一方法有其局限性，因此最近的研究尝试将深度学习方法与基于多视图约束的方法[6,9]或与场景流方法[8]相结合。我们的方法属于这一类。但是，我们不使用语义分段和nstance分段。我们使用轻量级的对象检测方法，该方法可以在CPU上运行，从而消除了对GPU的依赖。此外，我们提出了一种基于聚类的方法来加快基于多视图约束的检测过程。

> 基于k-means的方法？

#####  同时定位和密集映射

RGB-D传感器的出现使室内3D密集贴图负担得起。第一个突破性的工作是KinectFusion [13]。它使用粗到精的迭代最近点（ICP）[23]方法跟踪摄像机的运动，并将深度图像融合到截断的有符号距离函数（TSDF）[24]映射中。 TSDF贴图将3D空间划分为体素。每个体素都被编码为到最近曲面的距离。但是，大量的内存消耗和无循环关闭将应用程序场景限制为小规模。这些缺点随后通过后续工作得以解决[25,26]。与传统的SLAM方法不同，ElasticFusion [2]不会在闭环中优化姿势图，但会优化可变形图。此方法使用框架建模方法执行跟踪。它使用模型来实现局部和全局循环闭合方法。它的地图由surfel模型表示。但是，冲浪表示仅包含两种类型的信息，即自由信息和占用信息。勘探任务所需的未知信息不可用。此外，这些方法大多数都在GPU上实现以确保实时操作。相反，OctoMap可以在CPU上运行，并提供所有三种类型的信息：已占用，空闲和未知[14]。与TSDF相似，OctoMap将空间划分为体素。不同之处在于，OctoMap的每个体素都被赋予了占用概率，并且使用了贝叶斯过滤器通过多次测量来更新占用概率。更新策略可以过滤掉少量的动态数据。但是，OctoMap不可变形。
在循环闭合中完成姿势调整后，需要使用原始原始数据重建完整地图，这会占用大量存储空间和计算时间。

在本文中，我们使用子图表示。首先将原始数据集成到许多小的子图中。调整姿势后，我们只需要将这些子图重新组装成完整的图即可。该方法可以提高地图更新效率，减少内存消耗。 RTAB-MAP [15]使用类似的基于子图的表示来构造OctoMap。但是，其子图仅包含一帧。它没有分析子图大小和体素大小对重建时间和内存消耗的影响。 RGBDSLAMv2 [27]首先使用基于稀疏特征的SLAM获得高精度的相机姿态，然后基于这些姿态构造OctoMap。但是，此方法无法在姿势图更改后有效地更新密集地图。与RGBDSLAMv2相似，我们的方法还首先实现基于稀疏特征的SLAM，然后使用关键帧构造一个OctoMap。

不同之处在于我们的方法引入了编码器信息，实现了有效的OctoMap更新和环境。

#####  动态场景的同时定位和密集映射

动态环境的同时定位和密集映射系统可以分为三类。

第一种类型的系统检测并删除动态对象，并构建静态背景的密集图。 DynaSLAM [9]扩展了ORB-SLAM2 [1]的功能，可以在动态环境中构建静态密集点云图。该系统使用实例分割方法Mask-RCNN [28]，多视图约束或它们两者来检测每个RGB-D帧中的运动像素。但是，该系统不是实时的。此外，密集点云图对于机器人导航而言过于粗糙。 DS-SLAM [6]是从ORB-SLAM2派生的另一种算法。该系统使用语义分割方法SegNet [29]从RGB图像中检测人所在的像素。然后，通过移动一致性来检查落在人身上的特征，以确定它们是否是动态的。最终，使用深度图像中的静态像素构建基于OctoMap的语义图。该系统仅考虑预定义的动态对象，例如erson。 
StaticFusion [17]联合估计相机运动以及RGB-D图像对的概率静态/动态分割。分割然后用于融合基于surfel的静态背景模型。为了实现实时性能，作者将图像尺寸减小到320 x 240像素。此外，长时间处于静止状态的人可能会被检测为静止的并融合到地图上。上述大多数系统都需要强大的GPU支持。我们的系统属于这一类。

我们可以在CPU上运行，并检测预定义和未定义移动对象上的动态像素。第二类系统不仅构造了密集的静态背景，而且还跟踪运动对象[7,8,10]。该系统旨在支持动态环境中机器人的路径规划和操作任务。与它们不同，我们的目标是提供静态地图作为移动机器人导航的基本参考。

第二类系统不仅构造了密集的静态背景，而且还跟踪运动对象[7,8,10]。该系统旨在支持动态环境中机器人的路径规划和操作任务。与它们不同，我们的目标是提供静态地图作为移动机器人导航的基本参考。

第三类系统构建了一个非刚性的可变形环境[30,31]。但是，操作环境被限制在较小的区域。此外，非刚性可变形环境表示可能不适用于移动机器人，因为移动机器人拥有更大的操作空间和更多的环境变化。

#### Preliminaries

![20200806105849](https://chendaxiashizhu-1259416116.cos.ap-beijing.myqcloud.com/20200806105849.png)

#### Dynamic RGB-D Encoder SLAM (DRE-SLAM)

##### 系统说明

图2提供了建议的DRE-SLAM系统的概述。该系统利用两种类型的输入：RGB-D图像对和编码器测量。
输出是一系列机器人姿势和一个OctoMap。该系统基于基于稀疏特征的V-SLAM。结合编码器信息的添加和动态像素的剔除，我们为动态环境开发了稀疏的RGB-D ncoder SLAM。然后，我们基于关键帧构建一个OctoMap。流水线分为四个模块：RGB-D编码器跟踪，动态像素剔除，稀疏映射和OctoMap构建。

![20200806105826](https://chendaxiashizhu-1259416116.cos.ap-beijing.myqcloud.com/20200806105826.png)

RGB-D编码器跟踪。当RGB-D对{C，D}进入时，它将被构造为当前帧，然后将提取稀疏的ORB特征集。由于编码器的输出频率通常比摄像机的输出频率高得多，因此我们将编码器的测量结果整合到最后一个关键帧和当前帧之间，以获得当前帧的可靠初始机器人姿态，从而降低了计算复杂性。将3D局部地图点投影到当前帧以与2D ORB特征匹配。通过共同最小化投影误差和编码器误差来计算当前帧的机器人姿态。然后，确定当前帧是否成为新的关键帧。

动态像素剔除。在我们的系统中，仅关键帧用于构造OctoMap和稀疏映射。在动态环境中构建静态地图的关键是识别和删除动态像素。该模块首先使用对象检测方法检测彩色图像C中的预定义动态对象，然后使用多视图约束来识别深度图像D中的动态像素。将两种方法检测到的动态像素全部剔除。

稀疏映射。给定新的关键帧，此模块将执行滑动窗口局部包调整（BA），以最大程度地减少投影误差和编码器误差。这样，新关键帧的机器人姿势得以改善。改进后的新关键帧将发送到OctoMap构造模块。然后，我们构造新的地图点。之后，我们将检测新关键帧和历史关键帧之间的循环。
如果检测到回路，将执行姿势图优化。

OctoMap构建。该模块首先使用关键帧构造子OctoMap，然后将这些子OctoMap组装成完整的OctoMap。循环关闭完成后，我们只需要重新组装子OctoMap。我们的方法在六个分离的线程上运行以获得实时操作。
这些线程是RGB-D编码器跟踪，动态像素剔除，局部稀疏映射，循环闭合，sub-OctoMap构造和sub-OctoMap融合。

#####  *RGB-D Encoder Tracking*

1. ORB Feature Extraction

我们从Kinect 2.0相机产生的分辨率为960 x 540像素的图像中提取1600个ORB特征。请注意，当环境中的表面均匀或纹理较少时，我们可能无法提取图像中足够的特征。幸运的是，我们介绍了编码器信息，使系统在这些情况下能够正常工作。这些功能的2D位置组织在KD-Tree中，以加快搜索过程。均匀特征分布对于动态场景中的SLAM系统而言至关重要，因为它可以减少动态对象上的特征点数量，尤其是在动态对象包含丰富纹理的情况下。我们使用与ORB-SLAM2 [1]相同的特征检测策略来获得均匀的特征分布。该策略将映像划分为多个单元并检测每个单元中的功能。

2. Encoder Integration



##### *Dynamic Pixels Culling*

图4显示了动态像素剔除管线。对象检测和多视图几何约束被组合以检测新关键帧中的动态像素。

![20200806112733](https://chendaxiashizhu-1259416116.cos.ap-beijing.myqcloud.com/20200806112733.png)

<span style="color:blue;">**1. 对象检测**</span>

·我们从彩色图像中检测预定义的动态对象。在室内环境中，动态对象可能是人，猫，狗等。我们通过植入OpenCV的对象检测方法YOLOv3 [34]来检测这些预定义的动态对象。直接使用在COCO数据集上训练的公开可用模型[35]。 YOLOv3可以在我们的Intel i7-8700 CPU上每秒处理6-7个图像，而无需GPU。但是，可能会有一些漏检，尤其是在仅查看动态对象的一部分时，如图4所示。此外，某些未包含在预定义动态对象中的对象也可能正在移动，例如书籍，椅子和书桌。

因此，在下文中，提出了一种基于多视图约束的方法来使用深度图像检测动态像素，

<span style="color:blue;">**2. 基于多视图约束的动态像素剔除**</span>

如图4所示，首先剔除动态对象边界框中的像素。然后，将剩余的像素投影到3D以创建点云。
我们使用K-means方法将点云划分为几个集群。假定这些簇是刚体，这意味着同一簇中的像素具有相同的运动属性。该假设是合理的，因为我们专注于删除动态像素和构建静态地图，但不跟踪动态对象。群集数k是根据点云的大小sp确定的：k = sp / npt。 npt是要调整的群集的平均点数。减少npt可以保证更好的近似度，但同时也增加了计算负担。我们将npt设置为6000，以平衡计算量和精度。

我们只需要检测哪些集群是动态集群即可。为了加快动态群集检测过程，我们仅在群集中均匀选择少量像素（例如100个像素），然后使用多视图约束来判断其动态和静态属性。如果动态像素的数量很大，则将集群确定为动态的。否则，确定集群是静态的。我们通过将像素投影到最后的Npc关键帧（附近的关键帧）进行比较来检测像素是否是动态的。我们在本文中将Npc设置为5。使用深度图像中的深度z和新关键帧的机器人姿态T，将像素u反投影为世界帧中的3D点：

##### 稀疏映射 (与建图相关)

####  **Experiments**

本节通过在各种动态和静态环境中通过自收集数据评估提出的DRE-SLAM系统。 RedBot使用Rosbag工具[38]收集了数据，如图7所示。每个RedBot车轮都安装了一个编码器，该编码器以100 Hz的频率输出测量结果。 Kinect 2.0相机固定在机器人的正面。相机通过使用iai-kinect2驱动程序[39]以20 Hz的速度输出注册的RGB-D图像对，分辨率为960 x 540像素。我们用C ++实现了建议的DRE-SLAM，并在配备Intel Core i7-8700 CPU，16 GB RAM的计算机上进行了所有实验。操作系统是Ubuntu 16.04。

![20200806110459](https://chendaxiashizhu-1259416116.cos.ap-beijing.myqcloud.com/20200806110459.png)

##### *Comparative Tests*

本节在姿势准确性，地图质量和鲁棒性方面将建议的DRE-SLAM与其他三个最新的开源SLAM系统进行了比较。
选择的系统是RTAB-MAP [15]，StaticFusion [17]和Co-Fusion [7]。在GTX1070 GPU上执行了StaticFusion和Co-Fusion。由于在我们的实验中某些场景并不接近相机，因此对于这四种方法，我们都使用了距离深度图8.0 m以内的深度像素。其他特殊配置如下：

DRE-SLAM。在OctoMap构造模块中，OctoMap的体素大小设置为0.05 m，子图大小设置为五个关键帧。

RTAB-MAP。该系统将RGB-D图像和车轮里程表作为输入。我们集成了车轮编码器的测量值，以形成RTAB-MAP的车轮里程表。其OctoMap体素大小也设置为0.05 m。所有其他参数均设置为原始。

静态融合。该系统仅使用RGB-D图像，并输出基于静态surfel的背景图。原始实现是针对640 x 480像素的图像，该图像在程序中已降采样为320 x 240像素。我们修改了接口以接受960 x 540像素的图像，并且还在程序中将图像降采样为480 x 270像素。其他参数未更改。

共同融合。该系统构建基于surfel的背景图，仅使用RGB-D图像对跟踪运动对象。由于我们仅考虑背景构造，因此停用了其跟踪部分。

如图8所示，我们在三种不同的环境中收集数据：办公室（O），实验室（L）和走廊（C）。办公环境整洁。实验室环境凌乱，纹理和结构信息丰富。走廊环境到处都是白色的墙壁，几乎没有纹理和结构信息。在每个环境中，我们收集了三种类型的数据：静态（ST），低动态（LD）和高动态（HD）。在静态数据中，没有移动的对象。在低动态数据中，只有一个人在移动。在高动态数据中，三个人在移动。人员携带平板电脑，椅子或其他未定义的物体移动。目的是验证未定义对象上动态像素的识别能力。针对每种类型的数据收集了三个序列。

总共收集了27个序列用于比较测试。每个数据序列都使用环境类型和数据类型来命名。例如，O-ST1是在静态（ST）办公室（O）环境中收集的第一个序列。在所有这27个序列中测试了这四种方法。

![20200806111035](https://chendaxiashizhu-1259416116.cos.ap-beijing.myqcloud.com/20200806111035.png)

<span style="color:blue;">**Pose Accuracy**</span>

如图7所示，我们在RedBot的顶部安装了ArUco [40]标记，并使用固定的下视摄像头通过平面测量方法捕获标记以产生姿态地面真相[41]。绝对姿态误差（APE）度量标准用于通过evo工具[42]评估姿态准确性。结果显示在表1中。均方根误差（RMSE）比较器显示在图9中。可以看出，相对于其他三种方法，DRE-SLAM在大多数序列中获得了最高的准确性。此外，无论是在静态环境中还是在动态环境中，姿态误差都没有太大不同。这表明就姿势精度而言，DRE-SLAM很少受动态对象的影响。在大多数序列中，RTAB-MAP的位姿误差也相对较小。但是，姿势误差在办公室环境中的动态序列中会增加，尤其是在高动态序列中。这是因为RTAB-MAP在回路和邻近度检测中未考虑动态干扰，而DRE-SLAM消除了动态像素，因此不受动态对象的影响。此外，RTAB-MAP仅将车轮里程计用于当前机器人姿态估计，而DRE-SLAM将RGB-D骆驼信息与车轮编码器紧密耦合。在大多数序列中，StaticFusion都具有较大的姿势误差。 Co-Fusior在大多数静态环境中都会执行小错误，而在动态环境中错误会急剧增加。 StaticFusion和Co-Fusion中的大错误的原因可能是（1）场景距离太远或（2）没有编码器数据。这也表明使用编码器可以提高系统精度，尤其是在动态环境中。编码器信息的使用可以提供良好的先验和强约束。当静态像素丢失时，编码器还可以获得可靠的姿态估计。我们还在图10中提供了具有基本事实的DRE-SLAM的轨迹。DRE-SLAM的轨迹是平滑的，并且与基本事实非常吻合。

![20200806111249](https://chendaxiashizhu-1259416116.cos.ap-beijing.myqcloud.com/20200806111249.png)

![20200806111741](https://chendaxiashizhu-1259416116.cos.ap-beijing.myqcloud.com/20200806111741.png)

![20200806111756](https://chendaxiashizhu-1259416116.cos.ap-beijing.myqcloud.com/20200806111756.png)

<center style="font-size:14px;color:555555;text-decoration:underline">图9.在所有序列中，四种方法的（a）转换（m）和（b）旋转（rad）的均方根误差（RMSE）。</center> 

![20200806111839](https://chendaxiashizhu-1259416116.cos.ap-beijing.myqcloud.com/20200806111839.png)

![20200806111855](https://chendaxiashizhu-1259416116.cos.ap-beijing.myqcloud.com/20200806111855.png)

<center style=“font-size:14px;color:555555;text-decoration:underline">图10.在（a）办公室，（b）实验室和（c）走廊环境中，所提方法的轨迹与地面真实情况的比较。绝对姿态误差由颜色编码。</center> 

<span style="color:blue;">**地图质量**</span>

图11提供了由四种方法创建的所有图以及所有数据序列。 DRE-SLAM在大多数序列中构建了干净的背景图。
这些地图中没有明显的变形。这证明DRE-SLAM可以在动态和静态环境中可靠地构造静态映射。 RTAB-MAP可以在大多数静态序列中构建漂亮的图。但是，许多动态对象以低动态序列和高动态序列引入其映射中。
有些地图甚至包含明显的失真，例如O-HD1和C-ST2的地图。 StaticFusion可以在tatic和低动态实验室序列中获得漂亮的地图。这可以受益于实验室环境的丰富结构。

但是，在其他序列中，其映射会遭受很多失真。我们发现StaticFusion将许多静态像素视为动态像素。
共融合可以在大多数静态序列中构建正确的映射，但是这些映射在低动态序列和高动态序列中显然会造成混淆。我们还可以看到，融合编码器信息的DRE-SLAM和RTAB-MAP产生的失真更少。而纯RGB-D方法（静态融合和共融合）则可以创建变形更多的地图。此现象表明使用编码器有助于改善地图质量。地图的质量主要取决于关键帧的姿势精度和动态像素的剔除效果。图11中我们系统的声音地图质量进一步表明，我们的方法产生了很高的姿态精度和动态像素剔除效果。

![20200806112025](https://chendaxiashizhu-1259416116.cos.ap-beijing.myqcloud.com/20200806112025.png)

##### *5.2. Performance of Dynamic Pixels Culling*

图12给出了动态像素剔除模块的结果。除了预定义的动态对象（例如人）之外，环境中还存在未定义的移动对象（例如平板电脑和椅子）。 YOLOv3可以识别大多数预定义的对象，但是可能无法识别部分可见的对象（请参见图12中的第二列）。借助基于多视图约束的策略，我们可以处理泄漏识别和未定义的移动对象（请参见图12中的第一列）。但是，我们的方法也会产生错误的检测结果。

例如，在图12的第三列中，移动平板电脑一部分的像素被标识为静态像素。由于这些像素和地面上的某些像素通过K-means算法被分类为一个群集，而地面像素占大多数，因此我们的方法将这一群集确定为静态。这个问题可以通过增加簇数来解决，但是它也增加了计算量。此外，由于使用了固定的阈值，我们的方法无法检测出缓慢移动的不确定动态对象。少量的错误识别对于OctoMap的构造不会造成严重的问题，因为OctoMap使用了过滤器。仅当多次观察到体素为障碍物时，体素的占用概率才会足够高，以标记所占据的体素。

![20200806112132](https://chendaxiashizhu-1259416116.cos.ap-beijing.myqcloud.com/20200806112132.png)

图12.动态像素剔除模块的典型结果。
第一行包括预定义的动态对象检测结果。
第二行包括使用深度图像进行K均值分割的结果。
第三行显示了最终的动态像素检测结果。
红色像素是动态的，蓝色像素是静态的，黑色像素是深度值无效的像素。

##### 扩展测试

在本节中，我们将在8 m x 6 m的办公室，15 m x 9 m的大厅和37 m x 27 m的走廊中进一步测试建议的系统。
按照这些顺序，几个人以不同的速度和方向移动。从相机的角度来看，其中许多人的身体只有一部分。
有时，移动的人几乎占据了相机的整个视野。有一些门打开和关闭。这些顺序非常具有挑战性。 StaticFusion和Co-Fusion均失败。尽管RTAB-MAP可以工作，但其轨迹和地图仍包含许多扭曲。它的地图中有许多动态对象。
相反，如图13所示，DRE-SLAM成功执行了姿态估计，贴图构造和循环闭合的过程。机器人的轨迹很平滑，贴图没有明显的变形。大多数动态对象在地图中被滤除。

![20200806112251](https://chendaxiashizhu-1259416116.cos.ap-beijing.myqcloud.com/20200806112251.png)

##### OctoMap构建的性能

#### 结论

在本文中，我们提出了动态RGB-D编码器SLAM系统，即DRE-SLAM。该系统在动态和静态环境中均具有强大的功能和高精度。 DRE-SLAM将RGD摄像机和两个轮式编码器的测量值作为输入，并生成机器人姿态和静态背景OctoMap。该系统完全在CPU上运行，不需要GPU。所实现的鲁棒性和准确性归因于与编码器和RGB-D摄像机紧密结合的方法。通过将YOLOv3对象检测方法与基于多视图约束的方法相结合，我们不仅可以在预定义的动态对象上而且可以在未定义的动态对象上识别动态像素。通过剔除这些动态对象占用的像素，可以获得在动态环境中工作的能力。基于子图的OctoMap构建方法显着减少了重建时间和内存消耗。我们进一步发现，用于构造子OctoMap的关键帧数量对时间和内存成本影响很小。因此，我们可以减少子图中关键帧的数量，以减少地图失真，而不会增加过多的计算和内存负担。所提出的系统特别适合在室内动态环境中运行的移动机器人。

在以后的工作中，我们将在两个方向上扩展我们的系统。首先，我们将解决车轮打滑的问题，以提高耐用性和准确性。其次，我们将探讨跟踪动态对象的功能。

